{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Input, Dense, ZeroPadding2D, BatchNormalization, Flatten, MaxPooling2D, Conv2D, Activation\n",
    "from keras.models import Sequential, Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from skimage import io\n",
    "import uuid\n",
    "import datetime\n",
    "import random\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "from btdnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 28s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# model = btd_model((40, 40, 3))\n",
    "vgg19_model = VGG19(weights='imagenet', input_shape=(48, 48, 3), include_top = False)\n",
    "model = Sequential()\n",
    "for layer in vgg16_model.layers:\n",
    "    model.add(layer)\n",
    "\n",
    "model.layers.pop()\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 14,889,281\n",
      "Trainable params: 14,889,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.read_csv('/media/herval/Save/School/THB/Master/Semestre3/Projekt/data/processed/all_with_augmented/X_train.csv', header=None).values[:, 1:]\n",
    "Y_train_df = pd.read_csv('/media/herval/Save/School/THB/Master/Semestre3/Projekt/data/processed/all_with_augmented/Y_train.csv', header=None).values[:, 1]\n",
    "X_test_df = pd.read_csv('/media/herval/Save/School/THB/Master/Semestre3/Projekt/data/processed/all_with_augmented/X_test.csv', header=None).values[:, 1:]\n",
    "Y_test_df = pd.read_csv('/media/herval/Save/School/THB/Master/Semestre3/Projekt/data/processed/all_with_augmented/Y_test.csv', header=None).values[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertSavedMatrixToApplicableMatrixOfImages(matrix, old_size, new_size):\n",
    "    m = matrix.shape[0]\n",
    "\n",
    "    r = matrix[:, :1600]\n",
    "    g = matrix[:, 1600:3200]\n",
    "    b = matrix[:, 3200:4800]\n",
    "\n",
    "    r = r.reshape((m, old_size[0], old_size[1]))\n",
    "    g = g.reshape((m, old_size[0], old_size[1]))\n",
    "    b = b.reshape((m, old_size[0], old_size[1]))\n",
    "\n",
    "    data = np.zeros((m, old_size[0], old_size[1], 3), 'uint8')\n",
    "    reshaped_data = np.zeros((m, new_size[0], new_size[1], 3), 'uint8')\n",
    "\n",
    "    data[..., 0] = r\n",
    "    data[..., 1] = g\n",
    "    data[..., 2] = b\n",
    "\n",
    "    for i in range(m):\n",
    "        img = Image.fromarray(data[i], 'RGB')\n",
    "        img = img.resize(new_size, Image.BILINEAR)\n",
    "        reshaped_data[i] = np.asarray(img)\n",
    "\n",
    "    return reshaped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33812, 48, 48, 3) (5967, 48, 48, 3) (33812, 1) (5967, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = convertSavedMatrixToApplicableMatrixOfImages(X_train_df, (40, 40), (48, 48))\n",
    "X_test = convertSavedMatrixToApplicableMatrixOfImages(X_test_df, (40, 40), (48, 48))\n",
    "Y_train = Y_train_df.reshape((Y_train_df.size, 1))\n",
    "Y_test = Y_test_df.reshape((Y_test_df.size, 1))\n",
    "\n",
    "# X_train = X_train_df.reshape((X_train_df.shape[0], 40, 40, 3))\n",
    "# X_test = X_test_df.reshape((X_test_df.shape[0], 40, 40, 3))\n",
    "\n",
    "# for i in range(m):\n",
    "#     img = Image.fromarray(data[0], 'RGB')\n",
    "#     img = img.resize(new_size, Image.BILINEAR)\n",
    "#     reshaped_data[i] = np.asarray(img)\n",
    "\n",
    "# X_train[:] = np.asarray(X_train[:].resize((48, 48), Image.BILINEAR))\n",
    "\n",
    "X_train = X_train / 255.\n",
    "X_test = X_test / 255.\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgd = optimizers.SGD(lr=0.0005)\n",
    "model.compile(optimizer = \"adam\", loss = \"mean_squared_error\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 1152/33812 [>.............................] - ETA: 8:12 - loss: 0.2308 - acc: 0.6441"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "evals = dict()\n",
    "evals['id'] = list()\n",
    "evals['train_acc'] = list()\n",
    "evals['train_loss'] = list()\n",
    "evals['test_acc'] = list()\n",
    "evals['test_loss'] = list()\n",
    "evals['duration'] = list()\n",
    "for epoch in range(epochs):\n",
    "    begin = datetime.datetime.now()\n",
    "    random.seed(100)\n",
    "    \n",
    "    hist = model.fit(x = X_train, y = Y_train, epochs=1, batch_size=128)\n",
    "    \n",
    "    end = datetime.datetime.now()\n",
    "    \n",
    "    evals['id'].append(uuid.uuid4())\n",
    "    evals['duration'].append((end - begin).total_seconds())\n",
    "    evals['train_acc'].append(hist.history['acc'][0])\n",
    "    evals['train_loss'].append(hist.history['loss'][0])\n",
    "    \n",
    "    preds = model.evaluate(x = X_test, y = Y_test)\n",
    "    evals['test_acc'].append(preds[1])\n",
    "    evals['test_loss'].append(preds[0])\n",
    "    print('Test loss: {}, Test acc: {}'.format(preds[0], preds[1]))\n",
    "    model_json = model.to_json()\n",
    "    with open(\"./classificators/models/class_model_train_loss-{}_train_acc-{}_test_loss-{}_test_acc-{}_{}{}{}{}{}{}.json\".format(hist.history['loss'][0],\n",
    "                                                                               hist.history['acc'][0],\n",
    "                                                                               preds[0],\n",
    "                                                                               preds[1],\n",
    "                                                                               begin.day,\n",
    "                                                                               begin.month,\n",
    "                                                                               begin.year,\n",
    "                                                                               begin.hour,\n",
    "                                                                               begin.minute,\n",
    "                                                                               begin.second), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(\"./classificators/weights/class_weights_train_loss-{}_train_acc-{}_{}{}{}{}{}{}.h5\".format(hist.history['loss'][0],\n",
    "                                                                               hist.history['acc'][0],\n",
    "                                                                               preds[0],\n",
    "                                                                               preds[1],\n",
    "                                                                               begin.day,\n",
    "                                                                               begin.month,\n",
    "                                                                               begin.year,\n",
    "                                                                               begin.hour,\n",
    "                                                                               begin.minute,\n",
    "                                                                               begin.second))\n",
    "ids = np.array([evals['id']]).T\n",
    "durations = np.array([evals['duration']]).T\n",
    "train_accs = np.array([evals['train_acc']]).T\n",
    "train_losses = np.array([evals['train_loss']]).T\n",
    "test_accs = np.array([evals['test_acc']]).T\n",
    "test_losses = np.array([evals['test_loss']]).T\n",
    "\n",
    "perfs = np.concatenate((ids, durations, train_accs, train_losses, test_accs, test_losses), axis = 1)\n",
    "    \n",
    "performances = pd.DataFrame(perfs, columns = ['id', 'duration', 'train_acc', 'train_loss', 'test_acc', 'test_loss'])\n",
    "performances.to_csv('./performances/class_performances.csv', index = False, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.evaluate(x = X_test, y = Y_test)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(x = X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
